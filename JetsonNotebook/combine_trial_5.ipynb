{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Optimize road_following model\n",
    "> Skip if you already have trt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, create the model. This must match the model used in the interactive training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "CATEGORIES = ['apex']\n",
    "# Specify the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "\n",
    "# Modify the fully connected layers\n",
    "class ModifiedResNet18(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])  # Exclude the original FC layer\n",
    "        self.fc1 = nn.Linear(original_model.fc.in_features, 128)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the modified model\n",
    "model = ModifiedResNet18(resnet18)\n",
    "model.load_state_dict(torch.load('resnet18_road_follow.pth'))\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert and optimize the model using ``torch2trt`` for faster inference with TensorRT.  Please see the [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt) readme for more details.\n",
    "\n",
    "> This optimization process can take a couple minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt import torch2trt\n",
    "\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the optimized model using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trt.state_dict(), 'road_following_model_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the optimized model by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "CATEGORIES = ['apex']\n",
    "# Specify the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "road_model_trt = TRTModule()\n",
    "road_model_trt.load_state_dict(torch.load('road_following_model_trt.pth'))\n",
    "\n",
    "def detect_road(img_tensor):\n",
    "    return road_model_trt(img_tensor).detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Access YOLO via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def upload_image(api_url, img_bytes, throttle, steering, road_x, road_y):\n",
    "    files = {'image': ('image.jpg', img_bytes, 'image/jpeg')}\n",
    "    data = {\n",
    "        'throttle': throttle,\n",
    "        'steering': steering,\n",
    "        'road_x': road_x,\n",
    "        'road_y': road_y\n",
    "    }\n",
    "    response = requests.post(api_url, files=files, data=data)\n",
    "    response.raise_for_status()\n",
    "    detections = response.json()\n",
    "    return detections\n",
    "\n",
    "API_URL = 'http://192.168.45.247:8485/detect'  # Replace with your API URL\n",
    "\n",
    "def detect_traffic_sign(byte_jpeg, throttle, steering, road_x, road_y):\n",
    "    return upload_image(API_URL, byte_jpeg, throttle, steering, road_x, road_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "def bgr8_to_tensor(image):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the racecar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "\n",
    "car = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Constants for steering adjustments\n",
    "STEERING_GAIN_HIGH = -1.2\n",
    "THROTTLE_HIGH = -0.28\n",
    "STEERING_GAIN_LOW = -1.0\n",
    "THROTTLE_LOW = -0.20\n",
    "STEERING_BIAS = -0.05\n",
    "FRAME_QUEUE_SIZE = 16\n",
    "COUNT_NEED = int(FRAME_QUEUE_SIZE / 2) + 1\n",
    "\n",
    "# Define and initialize car_status and observation objects\n",
    "class CarStatus:\n",
    "    def __init__(self):\n",
    "        self.is_car_running = False\n",
    "        self.speed = THROTTLE_HIGH\n",
    "        self.steering_gain = STEERING_GAIN_HIGH\n",
    "\n",
    "class Observation:\n",
    "    def __init__(self):\n",
    "        self.current_time = 1\n",
    "        self.bgr8 = None\n",
    "        self.bgr8fixed = None\n",
    "        self.jpeg = None\n",
    "        self.road_output = None\n",
    "        self.traffic_sign_queue = deque(maxlen=FRAME_QUEUE_SIZE)\n",
    "        self.frame_index = 0\n",
    "        self.timer = Timer()\n",
    "        self.flag = Flag()\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.park = 1\n",
    "        self.s100 = 1\n",
    "        self.s50 = 1\n",
    "        self.stop = 1\n",
    "        self.traffic = 1\n",
    "\n",
    "class Flag:\n",
    "    def __init__(self):\n",
    "        self.park = False\n",
    "        self.s100 = False\n",
    "        self.s50 = False\n",
    "        self.stop = False\n",
    "        self.traffic = False\n",
    "        self.resume = False\n",
    "\n",
    "car_status = CarStatus()\n",
    "observation = Observation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the camera class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import cv2\n",
    "\n",
    "observation.bgr8 = camera.read()\n",
    "print(observation.bgr8.shape)\n",
    "observation.jpeg = bgr8_to_jpeg(observation.bgr8)\n",
    "image_widget.value = observation.jpeg\n",
    "# display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Start camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "\n",
    "camera.running = True\n",
    "\n",
    "def update_image(change):\n",
    "    observation.bgr8 = change['new']\n",
    "#     # Update the image widget\n",
    "#     byte_img = bgr8_to_jpeg(observation.bgr8)\n",
    "#     image_widget.value = byte_img\n",
    "\n",
    "# Attach the update_image function to the camera's value observer\n",
    "camera.observe(update_image, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921da134acd54b1aaba0660098bd3784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque, Counter\n",
    "import copy\n",
    "\n",
    "def set_speed_high():\n",
    "    \"\"\"Set car speed to high and adjust steering.\"\"\"\n",
    "    car.throttle = THROTTLE_HIGH\n",
    "    car_status.speed = car.throttle\n",
    "    car_status.steering_gain = STEERING_GAIN_HIGH\n",
    "\n",
    "def set_speed_low():\n",
    "    \"\"\"Set car speed to low and adjust steering.\"\"\"\n",
    "    car.throttle = THROTTLE_LOW\n",
    "    car_status.speed = car.throttle\n",
    "    car_status.steering_gain = STEERING_GAIN_LOW\n",
    "    \n",
    "def set_speed_zero():\n",
    "    car.throttle = 0.0\n",
    "    \n",
    "def resume_speed():\n",
    "    car.throttle = car_status.speed\n",
    "\n",
    "def hit_brake(seconds=1):\n",
    "    \"\"\"Stop the car for a specified number of seconds.\"\"\"\n",
    "    car.throttle = 0.0\n",
    "    time.sleep(seconds)\n",
    "    car.throttle = car_status.speed\n",
    "\n",
    "def park_car():\n",
    "    \"\"\"Perform a smooth parking maneuver.\"\"\"\n",
    "    car.throttle = -THROTTLE_HIGH\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Steer to the right\n",
    "    car.steering = 0.8\n",
    "    car.throttle = THROTTLE_HIGH\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Move backward while steering to the left\n",
    "    car.steering = -0.8\n",
    "    car.throttle = -THROTTLE_HIGH\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Steer to the right again\n",
    "    car.steering = 0.8\n",
    "    car.throttle = THROTTLE_HIGH\n",
    "    time.sleep(2.5)\n",
    "    \n",
    "    # Stop the car\n",
    "    car.throttle = 0.0\n",
    "    car.steering = 0.0\n",
    "    car_status.is_car_running = False\n",
    "\n",
    "\n",
    "def evaluate_observation():\n",
    "    # Make a deep copy of the bgr8 image\n",
    "    observation.bgr8fixed = copy.deepcopy(observation.bgr8)\n",
    "    \n",
    "    img_tensor = bgr8_to_tensor(observation.bgr8fixed).half()\n",
    "    observation.road_output = detect_road(img_tensor)\n",
    "\n",
    "    observation.jpeg = bgr8_to_jpeg(observation.bgr8fixed)\n",
    "    if (observation.frame_index % 2) == 1:\n",
    "        # Convert the image to a format suitable for upload (e.g., NumPy array)\n",
    "        sign_output = detect_traffic_sign(observation.jpeg, car.throttle, car.steering, observation.road_output[0], observation.road_output[1])\n",
    "        clear_output(wait=True)  # Clear the output\n",
    "        print(f'speed {car.throttle}')\n",
    "        print(sign_output)\n",
    "        # Add the detection to the queue\n",
    "        observation.traffic_sign_queue.append(sign_output)\n",
    "    observation.frame_index += 1\n",
    "\n",
    "    # Use Counter to count occurrences of each traffic sign\n",
    "    observation.counter = Counter(detection['cls'] for detection in observation.traffic_sign_queue if detection)\n",
    "\n",
    "    # Update flags based on detection counts\n",
    "    observation.flag.park = observation.counter['park'] >= COUNT_NEED and observation.current_time >= observation.timer.park\n",
    "    observation.flag.s100 = observation.counter['s100'] >= COUNT_NEED and observation.current_time >= observation.timer.s100\n",
    "    observation.flag.s50 = observation.counter['s50'] >= COUNT_NEED and observation.current_time >= observation.timer.s50\n",
    "    if observation.counter['stop'] >= COUNT_NEED:\n",
    "        observation.flag.stop = True\n",
    "    elif observation.flag.stop:\n",
    "        observation.flag.stop = False\n",
    "        observation.flag.resume = True\n",
    "    observation.flag.traffic = observation.counter['traffic'] >= COUNT_NEED and observation.current_time >= observation.timer.traffic\n",
    "\n",
    "    # Get the current time in seconds since the Unix epoch\n",
    "    observation.current_time = time.time()\n",
    "\n",
    "    cv2.circle(observation.bgr8fixed, (observation.road_output[0], observation.road_output[1]), 5, (0, 0, 255), -1)  # Red dot\n",
    "    # mutable class, change on observation.bgr8fixed will affect observation.jpeg\n",
    "    image_widget.value = observation.jpeg\n",
    "\n",
    "def take_action():\n",
    "    x = float(observation.road_output[0])\n",
    "    x_percent = (x - 112) / 112\n",
    "    if car_status.is_car_running:\n",
    "        car.steering = x_percent * car_status.steering_gain + STEERING_BIAS\n",
    "    \n",
    "    # React to traffic sign detections based on flags\n",
    "    if observation.flag.park:\n",
    "        newest_detection = observation.traffic_sign_queue[-1]\n",
    "        xmin = newest_detection['xmin']\n",
    "        if xmin > 30:\n",
    "            pass\n",
    "        if xmin > 15:\n",
    "            car.throttle = THROTTLE_LOW\n",
    "#         elif 0 <= xmin < 5:\n",
    "#             car.throttle = -THROTTLE_LOW\n",
    "        else:\n",
    "            # do whatever sign description\n",
    "            park_car()\n",
    "            sign_output = detect_traffic_sign(observation.jpeg, 0.0, 0.0, 112, 112)\n",
    "            observation.flag = Flag() # Fasle all flag\n",
    "    elif observation.flag.s100:\n",
    "        set_speed_high()\n",
    "        observation.timer.s100 = observation.current_time + 10\n",
    "    elif observation.flag.s50:\n",
    "        set_speed_low()\n",
    "        observation.timer.s50 = observation.current_time + 10\n",
    "    elif observation.flag.stop:\n",
    "        newest_detection = observation.traffic_sign_queue[-1]\n",
    "        xmin = newest_detection['xmin']\n",
    "        if xmin > 30:\n",
    "            pass\n",
    "        if xmin > 15:\n",
    "            car.throttle = THROTTLE_LOW\n",
    "#         elif 0 <= xmin < 5:\n",
    "#             car.throttle = -THROTTLE_LOW\n",
    "        else:\n",
    "            # do whatever sign description\n",
    "            car.throttle = 0\n",
    "    elif observation.flag.traffic:\n",
    "        newest_detection = observation.traffic_sign_queue[-1]\n",
    "        xmin = newest_detection['xmin']\n",
    "        if xmin > 30:\n",
    "            pass\n",
    "        if xmin > 15:\n",
    "            car.throttle = THROTTLE_LOW\n",
    "#         elif 0 <= xmin < 5:\n",
    "#             car.throttle = -THROTTLE_LOW\n",
    "        else:\n",
    "            # do whatever sign description\n",
    "            sign_output = detect_traffic_sign(observation.jpeg, 0.0, 0.0, 112, 112)\n",
    "            hit_brake(seconds=10)  # Brake then wait 10s then continue to run\n",
    "            observation.timer.traffic = time.time() + 10\n",
    "        pass\n",
    "    elif observation.flag.resume: # No longer detect \"STOP\" sign\n",
    "        print(\"resume\")\n",
    "        resume_speed()\n",
    "        observation.flag.resume = False\n",
    "    else:\n",
    "        # No traffic sign detected action\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed -0.2\n",
      "{'cls': 'park', 'confident': '0.9697', 'xmax': 21, 'xmin': 2, 'ymax': 85, 'ymin': 39}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    car_status = CarStatus()\n",
    "    observation = Observation()\n",
    "    car_status.is_car_running = True\n",
    "    set_speed_high()\n",
    "    while car_status.is_car_running:\n",
    "        evaluate_observation()\n",
    "        take_action()\n",
    "finally:\n",
    "    car_status.is_car_running = False\n",
    "    car.throttle = 0\n",
    "    car.steering = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    park_car()\n",
    "finally:\n",
    "    car_status.is_car_running = False\n",
    "    car.throttle = 0\n",
    "    car.steering = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update_image, names='value')\n",
    "camera.running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_camera(camera):\n",
    "    camera.running = False\n",
    "    camera.cap.release()  # Release the camera resource if applicable\n",
    "\n",
    "stop_camera(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
